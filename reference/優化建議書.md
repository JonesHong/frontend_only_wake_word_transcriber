# Frontend-Only Wake Word Transcriber 優化建議書

## 執行摘要

本文提出四大優化方案：
1. **音訊處理管道**：AudioWorklet + MediaStreamTrack.getSettings() 實現智能格式轉換
2. **Web Worker 架構**：將 CPU 密集型任務隔離，改善 UI 響應性
3. **雙模式語音識別**：Web Speech API（即時串流）+ Whisper（檔案處理）
4. **WebGPU 加速**：Whisper 與 ONNX 模型

## 一、當前問題與解決方案

| 問題 | 解決方案 |
|------|----------|
| 主執行緒阻塞 | Worker 架構隔離 ONNX 推論 |
| 音訊格式不一致 | AudioWorklet 自動轉換 |
| 單一語音識別 | 雙模式架構（串流/檔案） |
| 缺乏 GPU 加速 | WebGPU 整合（Whisper 優先） |

## 二、核心架構設計

### 2.1 音訊處理管道

```
麥克風輸入 (任意格式)
    ↓
MediaStreamTrack.getSettings() [檢測實際參數]
    ↓
AudioWorklet Processor [格式標準化]
    • 聲道轉換 (立體聲→單聲道)
    • 重採樣 (48kHz→16kHz)
    • 格式轉換 (Float32→Int16)
    ↓
分流處理
    ├─ 主執行緒: Web Speech API
    └─ Worker: Wake Word/VAD/Whisper
```

#### 關鍵實作：AudioInputManager

```javascript
class AudioInputManager {
    async initializeAudioInput() {
        const stream = await navigator.mediaDevices.getUserMedia({
            audio: { 
                sampleRate: { ideal: 16000 },
                channelCount: { ideal: 1 }
            }
        });
        
        const track = stream.getAudioTracks()[0];
        const actualSpec = track.getSettings();
        
        // 自動檢測是否需要轉換
        const needsResampling = actualSpec.sampleRate !== 16000;
        
        return { stream, actualSpec, needsResampling };
    }
}
```

### 2.2 Worker 架構

```javascript
class WorkerManager {
    async createWorker(type) {
        if (this.mode === 'worker') {
            return new Worker(`/js/workers/${type}.worker.js`, {
                type: 'module'
            });
        }
        // 降級到主執行緒
        return this.mainThreadFallback(type);
    }
}
```

### 2.3 雙模式語音識別

| 模式 | 使用場景 | 優勢 | 限制 |
|------|----------|------|------|
| **Web Speech API** | 即時對話、喚醒詞回應 | 延遲<100ms、無需載入模型 | 需要網路、隱私考量 |
| **Whisper** | 檔案轉譯、離線處理 | 高準確度、100+語言、離線 | 載入時間長、高資源消耗 |

#### 智能模式選擇

```javascript
class SpeechRecognitionManager {
    async determineMode(context) {
        if (context.type === 'file') return 'whisper';
        
        if (!navigator.onLine) return 'whisper';
        if (!this.webSpeechSupported()) return 'whisper';
        
        return 'webspeech'; // 預設
    }
}
```

## 三、WebGPU 加速策略

### 3.1 支援範圍
- **Whisper**: ✅ Transformers.js 內建 WebGPU（2-5x 加速）
- **ONNX 模型**: ✅ 支援 WebGPU，自動降級到 WASM

### 3.2 ONNX Runtime WebGPU 實作

#### HTML 引入方式
```html
<!-- 使用支援 WebGPU 的版本 -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@latest/dist/ort.webgpu.min.js"></script>
```

#### ES Module 引入方式
```javascript
// 動態載入：根據 WebGPU 可用性選擇版本
const ort = navigator.gpu 
    ? await import('onnxruntime-web/webgpu')
    : await import('onnxruntime-web');

// 創建 Session 時自動降級
const session = await ort.InferenceSession.create(modelPath, {
    executionProviders: ['webgpu', 'wasm'] // WebGPU 優先，自動降級到 WASM
});
```

#### 完整實作範例
```javascript
class ONNXModelLoader {
    async loadWithOptimalBackend(modelPath) {
        try {
            // 檢測 WebGPU 支援
            const hasWebGPU = 'gpu' in navigator;
            
            // 動態載入對應版本
            const ort = hasWebGPU 
                ? await import('onnxruntime-web/webgpu')
                : await import('onnxruntime-web');
            
            // 配置執行提供者
            const providers = hasWebGPU 
                ? ['webgpu', 'wasm'] // 優先 WebGPU
                : ['wasm'];          // 僅 WASM
            
            // 創建 Session
            const session = await ort.InferenceSession.create(modelPath, {
                executionProviders: providers,
                graphOptimizationLevel: 'all'
            });
            
            console.log(`ONNX Runtime backend: ${providers[0]}`);
            return session;
            
        } catch (error) {
            // WebGPU 失敗時自動降級
            if (error.message.includes('webgpu')) {
                console.warn('WebGPU 初始化失敗，降級到 WASM');
                const ort = await import('onnxruntime-web');
                return ort.InferenceSession.create(modelPath, {
                    executionProviders: ['wasm']
                });
            }
            throw error;
        }
    }
}
```

## 四、實施計劃

### 階段一：音訊管道（1週）
1. AudioInputManager 實作
2. AudioWorklet 格式轉換器
3. 音訊診斷工具

### 階段二：Worker 架構（1週）
1. WorkerManager 基礎架構
2. ML Inference Worker
3. 能力檢測與降級機制

### 階段三：雙模式語音（2週）
1. SpeechRecognitionManager
2. 模式切換邏輯
3. Whisper Worker（延遲載入）

### 階段四：WebGPU 整合（1週）
- Whisper WebGPU 支援
- ONNX Runtime WebGPU 整合
- 自動降級機制測試

### 階段五：UI 整合（1週）
1. 模式選擇器
2. 檔案上傳介面
3. 音訊診斷 UI

## 五、效能預期

### 5.1 改善指標

| 指標 | 現況 | 優化後 | 提升 |
|------|------|--------|------|
| UI 響應性 | 阻塞 | 流暢 | 80-90% |
| 語音延遲 | 200ms+ | <100ms | 50% |
| GPU 利用 | 0% | 30-50% | - |
| 記憶體使用 | 集中 | 分散 | -30% |

### 5.2 相容性

- **瀏覽器支援**: 100%（漸進降級）
- **Web Speech API**: Chrome/Edge
- **Whisper**: 所有現代瀏覽器
- **WebGPU**: Chrome 113+（自動降級）

## 六、關鍵技術細節

### 6.1 AudioWorklet 處理流程

```javascript
class AudioFormatProcessor extends AudioWorkletProcessor {
    process(inputs) {
        let data = inputs[0];
        data = this.convertToMono(data);
        data = this.resample(data);
        data = this.convertToInt16(data);
        
        this.port.postMessage({
            type: 'audio-data',
            data: data,
            sampleRate: 16000
        });
        
        return true;
    }
}
```

### 6.2 設定檔結構

```javascript
const Config = {
    execution: {
        mode: 'auto',
        preferWebGPU: true
    },
    speechRecognition: {
        defaultMode: 'webspeech',
        webspeech: { 
            language: 'zh-TW',
            continuous: true 
        },
        whisper: { 
            lazyLoad: true,
            model: 'Xenova/whisper-tiny'
        }
    }
};
```

## 七、風險管理

| 風險 | 緩解策略 |
|------|----------|
| WebGPU 相容性 | 自動降級到 WASM |
| Worker 通訊開銷 | SharedArrayBuffer 優化 |
| 模型載入時間 | 預載入與快取機制 |
| 網路依賴 | Whisper 離線降級 |

## 八、最佳實踐

### 開發建議
1. **總是使用** `getSettings()` 檢查音訊參數
2. **優先** AudioWorklet 處理音訊
3. **延遲載入** Whisper 模型
4. **提供** 音訊診斷工具

### 除錯工具

```javascript
function logAudioDiagnostics(track) {
    const settings = track.getSettings();
    console.table({
        'Sample Rate': settings.sampleRate,
        'Channels': settings.channelCount,
        'Needs Conversion': settings.sampleRate !== 16000
    });
}
```

## 九、結論

本優化方案的核心價值：

1. **音訊處理完整性**：自動適配各種設備
2. **雙模式彈性**：兼顧即時性與準確性
3. **漸進式架構**：確保所有環境可用
4. **未來擴展性**：預留 WebGPU 升級路徑

建議優先實施音訊管道和 Worker 架構，保持 Web Speech API 作為主要模式，逐步整合 Whisper 和 WebGPU 支援。

---

*版本：2.0.0（精簡版）*  
*更新：2025-08-08*